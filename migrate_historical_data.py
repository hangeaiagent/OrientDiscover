#!/usr/bin/env python3
"""
å†å²æ•°æ®è¿ç§»è„šæœ¬ - Pythonç‰ˆæœ¬
Historical Data Migration Script for Spot Map Albums System
"""

import sys
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional
import psycopg2
from urllib.parse import urlparse

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('/workspace/backend')

from local_attractions_db import local_attractions_db
from global_cities_db import GlobalCitiesDB

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Supabaseæ•°æ®åº“è¿æ¥ä¿¡æ¯
DATABASE_URL = "postgresql://postgres:JjcUcOgvzPb7cHMH@db.uobwbhvwrciaxloqdizc.supabase.co:5432/postgres"

class HistoricalDataMigrator:
    """å†å²æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self):
        self.conn = None
        self.global_db = GlobalCitiesDB()
        self.migration_stats = {
            'attractions_migrated': 0,
            'contents_migrated': 0,
            'media_migrated': 0,
            'errors': []
        }
    
    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            parsed = urlparse(DATABASE_URL)
            self.conn = psycopg2.connect(
                host=parsed.hostname,
                port=parsed.port,
                database=parsed.path[1:],
                user=parsed.username,
                password=parsed.password
            )
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def migrate_attraction(self, attraction_data: Dict, source: str) -> Optional[str]:
        """è¿ç§»å•ä¸ªæ™¯ç‚¹æ•°æ®"""
        try:
            cursor = self.conn.cursor()
            
            # æ’å…¥æ™¯ç‚¹ä¸»è¡¨æ•°æ®
            insert_attraction_sql = """
            INSERT INTO spot_attractions (
                name, location, category, country, city, address,
                opening_hours, ticket_price, booking_method, 
                main_image_url, video_url, created_at, updated_at
            ) VALUES (
                %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s, %s,
                %s, %s, %s, %s, %s, now(), now()
            ) RETURNING id;
            """
            
            cursor.execute(insert_attraction_sql, (
                attraction_data['name'],
                attraction_data['longitude'], 
                attraction_data['latitude'],
                attraction_data['category'],
                attraction_data['country'],
                attraction_data['city'],
                attraction_data.get('address', ''),
                attraction_data.get('opening_hours', ''),
                attraction_data.get('ticket_price', ''),
                attraction_data.get('booking_method', ''),
                attraction_data.get('image', attraction_data.get('main_image_url', '')),
                attraction_data.get('video', attraction_data.get('video_url', ''))
            ))
            
            attraction_id = cursor.fetchone()[0]
            
            # æ’å…¥ä¸­æ–‡æè¿°åˆ°å¤šè¯­è¨€å†…å®¹è¡¨
            description = attraction_data.get('description', '')
            if description and description.strip():
                insert_content_sql = """
                INSERT INTO spot_attraction_contents (
                    attraction_id, language_code, name_translated, 
                    description, attraction_introduction, created_at
                ) VALUES (%s, %s, %s, %s, %s, now());
                """
                
                cursor.execute(insert_content_sql, (
                    attraction_id,
                    'zh-CN',
                    attraction_data['name'],
                    description,
                    description  # å°†descriptionåŒæ—¶ä½œä¸ºintroduction
                ))
                self.migration_stats['contents_migrated'] += 1
            
            # æ’å…¥åª’ä½“èµ„æº
            media_count = 0
            
            # æ’å…¥ä¸»å›¾ç‰‡
            image_url = attraction_data.get('image', attraction_data.get('main_image_url', ''))
            if image_url and image_url.strip():
                insert_media_sql = """
                INSERT INTO spot_attraction_media (
                    attraction_id, media_type, url, caption, 
                    is_primary, order_index, created_at
                ) VALUES (%s, %s, %s, %s, %s, %s, now());
                """
                
                cursor.execute(insert_media_sql, (
                    attraction_id,
                    'image',
                    image_url,
                    'æ™¯ç‚¹ä¸»å›¾ç‰‡',
                    True,
                    0
                ))
                media_count += 1
            
            # æ’å…¥è§†é¢‘
            video_url = attraction_data.get('video', attraction_data.get('video_url', ''))
            if video_url and video_url.strip():
                cursor.execute(insert_media_sql, (
                    attraction_id,
                    'video', 
                    video_url,
                    'æ™¯ç‚¹ä»‹ç»è§†é¢‘',
                    False,
                    1
                ))
                media_count += 1
            
            self.migration_stats['media_migrated'] += media_count
            self.conn.commit()
            cursor.close()
            
            self.migration_stats['attractions_migrated'] += 1
            logger.info(f"âœ… è¿ç§»æ™¯ç‚¹æˆåŠŸ: {attraction_data['name']} (æ¥æº: {source})")
            
            return attraction_id
            
        except Exception as e:
            error_msg = f"è¿ç§»æ™¯ç‚¹å¤±è´¥: {attraction_data.get('name', 'Unknown')} - {str(e)}"
            logger.error(error_msg)
            self.migration_stats['errors'].append(error_msg)
            self.conn.rollback()
            return None
    
    def migrate_local_attractions(self):
        """è¿ç§»æœ¬åœ°åŒ—äº¬æ™¯ç‚¹æ•°æ®"""
        logger.info("å¼€å§‹è¿ç§»æœ¬åœ°åŒ—äº¬æ™¯ç‚¹æ•°æ®...")
        
        local_attractions = local_attractions_db.attractions
        for attraction in local_attractions:
            self.migrate_attraction(attraction, "LocalAttractionsDB")
        
        logger.info(f"æœ¬åœ°æ™¯ç‚¹è¿ç§»å®Œæˆ: {len(local_attractions)} ä¸ªæ™¯ç‚¹")
    
    def migrate_global_attractions(self):
        """è¿ç§»å…¨çƒåŸå¸‚æ™¯ç‚¹æ•°æ®"""
        logger.info("å¼€å§‹è¿ç§»å…¨çƒåŸå¸‚æ™¯ç‚¹æ•°æ®...")
        
        total_migrated = 0
        
        # è¿ç§»å…¨çƒåŸå¸‚æ™¯ç‚¹
        for city_key, city_data in self.global_db.global_cities.items():
            logger.info(f"è¿ç§»åŸå¸‚: {city_data['name']} ({city_data['country']})")
            
            for attraction in city_data['attractions']:
                self.migrate_attraction(attraction, f"GlobalCitiesDB-{city_key}")
                total_migrated += 1
        
        # è¿ç§»ä¸­å›½å…¶ä»–åŸå¸‚æ™¯ç‚¹
        for city_key, city_data in self.global_db.china_cities.items():
            # è·³è¿‡åŒ—äº¬ï¼ˆå·²åœ¨æœ¬åœ°æ•°æ®ä¸­å¤„ç†ï¼‰
            if city_key == "beijing":
                continue
                
            if isinstance(city_data['attractions'], list):
                logger.info(f"è¿ç§»åŸå¸‚: {city_data['name']} ({city_data['country']})")
                
                for attraction in city_data['attractions']:
                    self.migrate_attraction(attraction, f"ChinaCitiesDB-{city_key}")
                    total_migrated += 1
        
        logger.info(f"å…¨çƒæ™¯ç‚¹è¿ç§»å®Œæˆ: {total_migrated} ä¸ªæ™¯ç‚¹")
    
    def validate_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        logger.info("å¼€å§‹éªŒè¯è¿ç§»ç»“æœ...")
        
        try:
            cursor = self.conn.cursor()
            
            # ç»Ÿè®¡å„è¡¨è®°å½•æ•°
            validation_queries = {
                'æ™¯ç‚¹æ€»æ•°': 'SELECT COUNT(*) FROM spot_attractions',
                'å¤šè¯­è¨€å†…å®¹æ€»æ•°': 'SELECT COUNT(*) FROM spot_attraction_contents',
                'åª’ä½“èµ„æºæ€»æ•°': 'SELECT COUNT(*) FROM spot_attraction_media',
                'å›½å®¶æ•°é‡': 'SELECT COUNT(DISTINCT country) FROM spot_attractions',
                'åŸå¸‚æ•°é‡': 'SELECT COUNT(DISTINCT city) FROM spot_attractions',
                'ç±»åˆ«æ•°é‡': 'SELECT COUNT(DISTINCT category) FROM spot_attractions'
            }
            
            validation_results = {}
            for metric, query in validation_queries.items():
                cursor.execute(query)
                count = cursor.fetchone()[0]
                validation_results[metric] = count
                logger.info(f"âœ… {metric}: {count}")
            
            # æŒ‰å›½å®¶ç»Ÿè®¡
            cursor.execute("""
                SELECT country, COUNT(*) 
                FROM spot_attractions 
                GROUP BY country 
                ORDER BY COUNT(*) DESC
            """)
            
            country_stats = cursor.fetchall()
            logger.info("æŒ‰å›½å®¶ç»Ÿè®¡:")
            for country, count in country_stats:
                logger.info(f"  - {country}: {count} ä¸ªæ™¯ç‚¹")
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            cursor.execute("""
                SELECT category, COUNT(*) 
                FROM spot_attractions 
                GROUP BY category 
                ORDER BY COUNT(*) DESC
            """)
            
            category_stats = cursor.fetchall()
            logger.info("æŒ‰ç±»åˆ«ç»Ÿè®¡:")
            for category, count in category_stats:
                logger.info(f"  - {category}: {count} ä¸ªæ™¯ç‚¹")
            
            cursor.close()
            
            # ä¿å­˜éªŒè¯ç»“æœ
            self.migration_stats['validation_results'] = validation_results
            self.migration_stats['country_stats'] = dict(country_stats)
            self.migration_stats['category_stats'] = dict(category_stats)
            
            return validation_results
            
        except Exception as e:
            logger.error(f"éªŒè¯è¿ç§»ç»“æœå¤±è´¥: {e}")
            return None
    
    def generate_migration_report(self):
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = {
            'migration_timestamp': datetime.now().isoformat(),
            'migration_summary': {
                'attractions_migrated': self.migration_stats['attractions_migrated'],
                'contents_migrated': self.migration_stats['contents_migrated'],
                'media_migrated': self.migration_stats['media_migrated'],
                'errors_count': len(self.migration_stats['errors'])
            },
            'validation_results': self.migration_stats.get('validation_results', {}),
            'country_statistics': self.migration_stats.get('country_stats', {}),
            'category_statistics': self.migration_stats.get('category_stats', {}),
            'errors': self.migration_stats['errors']
        }
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = f"/workspace/migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¿ç§»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return report
    
    def run_migration(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®è¿ç§»æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å†å²æ•°æ®è¿ç§»...")
        
        # è¿æ¥æ•°æ®åº“
        if not self.connect_database():
            logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œç»ˆæ­¢è¿ç§»")
            return False
        
        try:
            # è¿ç§»æœ¬åœ°æ™¯ç‚¹æ•°æ®
            self.migrate_local_attractions()
            
            # è¿ç§»å…¨çƒæ™¯ç‚¹æ•°æ®
            self.migrate_global_attractions()
            
            # éªŒè¯è¿ç§»ç»“æœ
            self.validate_migration()
            
            # ç”Ÿæˆè¿ç§»æŠ¥å‘Š
            report = self.generate_migration_report()
            
            logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼")
            logger.info(f"æ€»è®¡è¿ç§»æ™¯ç‚¹: {self.migration_stats['attractions_migrated']} ä¸ª")
            logger.info(f"æ€»è®¡è¿ç§»å†…å®¹: {self.migration_stats['contents_migrated']} æ¡")
            logger.info(f"æ€»è®¡è¿ç§»åª’ä½“: {self.migration_stats['media_migrated']} ä¸ª")
            
            if self.migration_stats['errors']:
                logger.warning(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿ {len(self.migration_stats['errors'])} ä¸ªé”™è¯¯")
                for error in self.migration_stats['errors']:
                    logger.warning(f"  - {error}")
            
            return True
            
        except Exception as e:
            logger.error(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            return False
        
        finally:
            if self.conn:
                self.conn.close()
                logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    migrator = HistoricalDataMigrator()
    success = migrator.run_migration()
    
    if success:
        logger.info("âœ… è¿ç§»ä»»åŠ¡æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        logger.error("âŒ è¿ç§»ä»»åŠ¡å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()